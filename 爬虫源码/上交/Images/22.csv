,box,txt,score
0,"[[159.0, 72.0], [402.0, 72.0], [402.0, 129.0], [159.0, 129.0]]",上海交通大学,0.8380905985832214
1,"[[567.0, 89.0], [889.0, 89.0], [889.0, 120.0], [567.0, 120.0]]",电子信息与电气工程学院,0.9462878704071045
2,"[[945.0, 98.0], [1102.0, 98.0], [1102.0, 137.0], [945.0, 137.0]]",学术报告,0.9413563013076782
3,"[[943.0, 173.0], [996.0, 173.0], [996.0, 212.0], [943.0, 212.0]]",系,0.9969527721405029
4,"[[1043.0, 175.0], [1103.0, 175.0], [1103.0, 212.0], [1043.0, 212.0]]",列,0.988192617893219
5,"[[65.0, 201.0], [854.0, 201.0], [854.0, 238.0], [65.0, 238.0]]",Talk title: Learning visual representation for,0.9216673374176025
6,"[[245.0, 260.0], [793.0, 260.0], [793.0, 297.0], [245.0, 297.0]]",image recognition/generation,0.9158573746681213
7,"[[389.0, 343.0], [910.0, 343.0], [910.0, 374.0], [389.0, 374.0]]",时间：2020年1月2日下午1：30,0.9848244786262512
8,"[[389.0, 387.0], [736.0, 387.0], [736.0, 419.0], [389.0, 419.0]]",地点：电院3号楼404,0.9436050653457642
9,"[[388.0, 433.0], [1113.0, 435.0], [1113.0, 467.0], [387.0, 465.0]]","演讲人:Boyi Li, CS PhD student, Cornell University",0.9153886437416077
10,"[[395.0, 491.0], [550.0, 491.0], [550.0, 524.0], [395.0, 524.0]]",Abstract:,0.9954136610031128
11,"[[450.0, 541.0], [1124.0, 541.0], [1124.0, 572.0], [450.0, 572.0]]",Visual Representation has received a lot of,0.9323559999465942
12,"[[389.0, 585.0], [1126.0, 587.0], [1126.0, 618.0], [389.0, 616.0]]",attention from both academia and industry in recent,0.9330699443817139
13,"[[386.0, 631.0], [1124.0, 627.0], [1124.0, 664.0], [386.0, 668.0]]",years. This talk will briefly cover our previous,0.9382858872413635
14,"[[389.0, 679.0], [1122.0, 679.0], [1122.0, 710.0], [389.0, 710.0]]",research targeting at digging out the relationship,0.9531340599060059
15,"[[57.0, 719.0], [1120.0, 723.0], [1120.0, 755.0], [57.0, 751.0]]","between low-level visual representation and high-level recognition tasks,",0.9238719344139099
16,"[[57.0, 769.0], [1122.0, 769.0], [1122.0, 801.0], [57.0, 801.0]]",as well as our current research focusing on a new normalization method,0.9304009675979614
17,"[[59.0, 814.0], [1122.0, 814.0], [1122.0, 845.0], [59.0, 845.0]]",which could be applied to most generative models to help preserve or,0.9382404685020447
18,"[[59.0, 860.0], [1124.0, 860.0], [1124.0, 891.0], [59.0, 891.0]]","transfer structural information. During the talk, I will present AOD-Net and",0.9298534393310547
19,"[[55.0, 946.0], [1124.0, 948.0], [1124.0, 985.0], [55.0, 983.0]]","bridge the gap between theory and practice, in realizing an efficient model",0.9303290843963623
20,"[[57.0, 996.0], [563.0, 996.0], [563.0, 1028.0], [57.0, 1028.0]]",for recognition or creating the world.,0.9189450144767761
21,"[[54.0, 1055.0], [131.0, 1055.0], [131.0, 1096.0], [54.0, 1096.0]]",Bio:,0.998753011226654
22,"[[59.0, 1155.0], [1120.0, 1155.0], [1120.0, 1186.0], [59.0, 1186.0]]",by Prof. Serge Belongie and Prof. Kilian Q. Weinberger. Her interest spans,0.9126468300819397
23,"[[57.0, 1201.0], [1120.0, 1201.0], [1120.0, 1232.0], [57.0, 1232.0]]","in Machine Learning, Computer Vision and Multimedia Art. In detail, she is",0.9305404424667358
24,"[[57.0, 1249.0], [205.0, 1247.0], [205.0, 1280.0], [58.0, 1282.0]]",generally,0.9988188147544861
25,"[[225.0, 1243.0], [1024.0, 1247.0], [1024.0, 1284.0], [225.0, 1280.0]]",interestedinvisualrepresentationlearning,0.9568576812744141
26,"[[1059.0, 1247.0], [1124.0, 1247.0], [1124.0, 1280.0], [1059.0, 1280.0]]", and,0.8715015649795532
27,"[[55.0, 1293.0], [1067.0, 1291.0], [1067.0, 1328.0], [55.0, 1330.0]]","generative/recognition models. Currently,Shefocusesmore",0.9273187518119812
28,"[[1063.0, 1299.0], [1124.0, 1299.0], [1124.0, 1326.0], [1063.0, 1326.0]]",on,0.9945335984230042
29,"[[54.0, 1336.0], [1124.0, 1337.0], [1124.0, 1374.0], [53.0, 1373.0]]",fundamental problems of generative/recognition models using deep,0.9493563175201416
30,"[[56.0, 1381.0], [181.0, 1386.0], [180.0, 1419.0], [55.0, 1415.0]]",learning.,0.984893798828125
