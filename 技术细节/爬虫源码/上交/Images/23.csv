,box,txt,score
0,"[[159.0, 72.0], [402.0, 72.0], [402.0, 129.0], [159.0, 129.0]]",上海交通大学,0.8380905985832214
1,"[[565.0, 89.0], [889.0, 87.0], [890.0, 118.0], [565.0, 120.0]]",电子信息与电气工程学院,0.9475967884063721
2,"[[945.0, 98.0], [1102.0, 98.0], [1102.0, 137.0], [945.0, 137.0]]",学术报告,0.9413563013076782
3,"[[157.0, 133.0], [395.0, 131.0], [395.0, 151.0], [157.0, 153.0]]",SHANGHAI JIAO TONG UNIVERSITY,0.9397392868995667
4,"[[943.0, 173.0], [998.0, 173.0], [998.0, 212.0], [943.0, 212.0]]",系,0.9965707063674927
5,"[[1037.0, 175.0], [1103.0, 175.0], [1103.0, 212.0], [1037.0, 212.0]]",列,0.9895389676094055
6,"[[107.0, 214.0], [847.0, 216.0], [847.0, 255.0], [107.0, 253.0]]",Title:Towards End-to-End Speech Synthesis,0.9533947110176086
7,"[[404.0, 315.0], [1116.0, 315.0], [1116.0, 347.0], [404.0, 347.0]]","Speaker: Yu Zhang, Research scientist at Google",0.9330150485038757
8,"[[406.0, 363.0], [875.0, 363.0], [875.0, 389.0], [406.0, 389.0]]",Time:14:00-16:00Jan15th.2020,0.9213952422142029
9,"[[404.0, 408.0], [810.0, 408.0], [810.0, 439.0], [404.0, 439.0]]","Venue:Room 412,SEIEE-3",0.8746917247772217
10,"[[402.0, 456.0], [766.0, 456.0], [766.0, 487.0], [402.0, 487.0]]",Host: Prof. Yanming Qian,0.9435511231422424
11,"[[406.0, 537.0], [563.0, 537.0], [563.0, 570.0], [406.0, 570.0]]",Abstract:,0.9636486768722534
12,"[[452.0, 594.0], [1118.0, 596.0], [1118.0, 627.0], [452.0, 625.0]]",Neural network -based system for text-to-,0.9492313265800476
13,"[[59.0, 644.0], [1122.0, 644.0], [1122.0, 675.0], [59.0, 675.0]]",speech (TTS) synthesis that is able to generate speech audio in the voice,0.9359337687492371
14,"[[57.0, 688.0], [1122.0, 690.0], [1122.0, 721.0], [57.0, 719.0]]",of different speakers and learn to model a large range of acoustic,0.935333251953125
15,"[[59.0, 738.0], [1122.0, 738.0], [1122.0, 769.0], [59.0, 769.0]]","expressiveness, such as speed and speaking style. Building on these",0.9426279067993164
16,"[[55.0, 782.0], [1118.0, 786.0], [1118.0, 817.0], [55.0, 814.0]]","successes, I will describe several recent results demonstrating sequence-",0.9551289081573486
17,"[[59.0, 834.0], [1120.0, 834.0], [1120.0, 860.0], [59.0, 860.0]]",to-sequence model basedTTSmodel opensnewdirectionforthe speech,0.892519474029541
18,"[[59.0, 880.0], [1122.0, 880.0], [1122.0, 911.0], [59.0, 911.0]]","synthesis community, including multi-speaker, global/local prosody control",0.9473122358322144
19,"[[57.0, 924.0], [736.0, 926.0], [736.0, 957.0], [57.0, 956.0]]",and potential application for speech recognition.,0.917866051197052
20,"[[57.0, 1001.0], [134.0, 1006.0], [131.0, 1049.0], [55.0, 1043.0]]",Bio:,0.9988605380058289
21,"[[122.0, 1064.0], [1120.0, 1064.0], [1120.0, 1096.0], [122.0, 1096.0]]","Yu Zhang is a research scientist at Google, where his research",0.956773579120636
22,"[[57.0, 1114.0], [1122.0, 1114.0], [1122.0, 1146.0], [57.0, 1146.0]]",focuses on improving ML model performance for various speech,0.9305106401443481
23,"[[59.0, 1160.0], [1122.0, 1160.0], [1122.0, 1192.0], [59.0, 1192.0]]","processing applications. Currently, he is working on end-to-end ASR and",0.9235346913337708
24,"[[61.0, 1206.0], [1122.0, 1206.0], [1122.0, 1238.0], [61.0, 1238.0]]","TTS. Before coming to Google, he completed his Ph.D. at Massachusetts",0.9386065006256104
25,"[[57.0, 1251.0], [1122.0, 1251.0], [1122.0, 1288.0], [57.0, 1288.0]]","Institute of Technology, where his advisor was James Glass. Most of his",0.9175058007240295
26,"[[55.0, 1297.0], [1122.0, 1302.0], [1122.0, 1334.0], [55.0, 1328.0]]",Ph.D. work has been focused on automatic speech recognition using,0.9371086955070496
27,"[[59.0, 1349.0], [290.0, 1349.0], [290.0, 1374.0], [59.0, 1374.0]]",neural networks.,0.9545125961303711
